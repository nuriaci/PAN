{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4. Anonymity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Union, List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data handling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_toy_dataset(**kwargs):\n",
    "    '''\n",
    "    Builds a toy dataset with fixed records.\n",
    "    \n",
    "    Returns:\n",
    "    - A tuple containing:\n",
    "        * Dataset as a Pandas Dataframe\n",
    "        * List of quasi-identifiers\n",
    "        * Sensitive column name\n",
    "    '''\n",
    "    data = [\n",
    "        [6, \"1\", \"test1\", \"x\", 20],\n",
    "        [6, \"1\", \"test1\", \"x\", 30],\n",
    "        [8, \"2\", \"test2\", \"x\", 50],\n",
    "        [8, \"2\", \"test3\", \"w\", 45],\n",
    "        [8, \"1\", \"test2\", \"y\", 35],\n",
    "        [4, \"2\", \"test3\", \"y\", 20],\n",
    "        [4, \"1\", \"test3\", \"y\", 20],\n",
    "        [2, \"1\", \"test3\", \"z\", 22],\n",
    "        [2, \"2\", \"test3\", \"y\", 32],\n",
    "    ]\n",
    "\n",
    "    columns = [\"col1\", \"col2\", \"col3\", \"col4\", \"col5\"]\n",
    "    categorical = set((\"col2\", \"col3\", \"col4\"))\n",
    "\n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "\n",
    "\n",
    "    for name in categorical:\n",
    "        df[name] = df[name].astype(\"category\")\n",
    "\n",
    "    return df, [\"col1\", \"col2\", \"col3\"], 'col4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_dataset(n: int=200, **kwargs):\n",
    "    '''\n",
    "    Generates a toy dataset containing n distinct samples.\n",
    "\n",
    "    - n: number of samples to generate\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing:\n",
    "        * Dataset as a Pandas Dataframe\n",
    "        * List of quasi-identifiers\n",
    "        * Sensitive column name\n",
    "    '''\n",
    "    diseases = np.array([\"Angine\", \"Appendicite\", \"Chlamydia\", \"Cataracte\", \"Dengue\", \n",
    "                         \"Eczéma\", \"Grippe\", \"Hépatite B\", \"Hépatite C\", \"Rhino-pharyngite\", \n",
    "                         \"Otite\", \"Rougeole\", \"Scarlatine\", \"Urticaire\", \"Varicelle\", \"Zona\"])\n",
    "    zipcodes = np.array([35000, 35200, 37000, 40000, 40500, 50000, 52000, 60000, 62000, 68000, \n",
    "                         75000, 75001, 75002, 75005])\n",
    "\n",
    "    rows = []\n",
    "    for _ in range(n):\n",
    "        row = {'Age':np.random.randint(7, 77), 'ZipCode':np.random.choice(zipcodes), 'Disease':np.random.choice(diseases)}\n",
    "        while row in rows:\n",
    "            row = {'Age':np.random.randint(7, 77), 'ZipCode':np.random.choice(zipcodes), 'Disease':np.random.choice(diseases)}\n",
    "        rows.append(row)\n",
    "        \n",
    "        \n",
    "    dataset = pd.DataFrame(rows)\n",
    "    dataset.sort_values(by = ['Age', 'ZipCode'], inplace=True)\n",
    "\n",
    "    return dataset, ['Age', 'ZipCode'], 'Disease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_adult(path: str, **kwargs) -> pd.DataFrame:\n",
    "    '''\n",
    "    Reads the adult dataset.\n",
    "\n",
    "    Parameters:\n",
    "        - path: path to the CSV file\n",
    "    \n",
    "    Returns:\n",
    "    - A tuple containing:\n",
    "        * Dataset as a Pandas Dataframe\n",
    "        * List of quasi-identifiers\n",
    "        * Sensitive column name\n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv(path, header=0, index_col=None, sep=',')\n",
    "    categorical = ['workclass', 'education', 'marital.status', 'occupation',\n",
    "        'race', 'sex', 'native.country']\n",
    "    for name in categorical:\n",
    "        df[name] = df[name].astype(\"category\")\n",
    "\n",
    "    return df, ['age', 'workclass', 'education', 'marital.status', 'occupation',\n",
    "        'race', 'sex', 'native.country'], 'income'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(type='toy', **kwargs):\n",
    "    '''\n",
    "    Build data\n",
    "\n",
    "    Parameters:\n",
    "        - type: toy, random or adult\n",
    "        - kwargs: arguments for the underlying data generation functions\n",
    "    \n",
    "    Returns:\n",
    "    - A tuple containing:\n",
    "        * Dataset as a Pandas Dataframe\n",
    "        * List of quasi-identifiers\n",
    "        * Sensitive column name\n",
    "    '''\n",
    "\n",
    "    if type == 'toy':\n",
    "        return build_toy_dataset()\n",
    "    elif type == 'random':\n",
    "        return generate_random_dataset(**kwargs)\n",
    "    elif type == 'adult':\n",
    "        return read_adult(**kwargs)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k(CHANGE_ME):\n",
    "    '''\n",
    "    Obtains the number of different rows within a partition.\n",
    "\n",
    "    Parameters:\n",
    "        ...\n",
    "\n",
    "    Returns:\n",
    "        - K parameter for k-anonymity\n",
    "    '''\n",
    "    ...\n",
    "\n",
    "def get_l(CHANGE_ME):\n",
    "    '''\n",
    "    Gets the number of different sensitive values within a partition.\n",
    "\n",
    "    Parameters:\n",
    "        ...\n",
    "\n",
    "    Returns:\n",
    "        - L parameter for l-diversity\n",
    "    '''\n",
    "    ...\n",
    "\n",
    "def get_t(CHANGE_ME):\n",
    "    '''\n",
    "    Gets the distance between the distribution of the sensitive column within\n",
    "    the partition with respect to the global distribution.\n",
    "\n",
    "    Parameters:\n",
    "        ...\n",
    "    \n",
    "    Returns:\n",
    "        - T parameter for t-closeness\n",
    "    '''\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_k_anonymous(CHANGE_ME, k: int):\n",
    "    '''\n",
    "    Checks if a partition is k-anonymous.\n",
    "\n",
    "    Parameters:\n",
    "        ...\n",
    "        - k: number of different rows per partition\n",
    "\n",
    "    Returns:\n",
    "        - True if the partition satisfies k-anonymity. False otherwise\n",
    "    '''\n",
    "    ...\n",
    "\n",
    "def is_l_diverse(CHANGE_ME, l: int):\n",
    "    '''\n",
    "    Checks if a partition is l-diverse.\n",
    "\n",
    "    Parameters:\n",
    "        ...\n",
    "        - l: number of distinct values for the sensitive column within the partition\n",
    "\n",
    "    Returns:\n",
    "        - True if the partition satisfies l-diversity. False otherwise\n",
    "    '''\n",
    "    ...\n",
    "\n",
    "def is_t_close(CHANGE_ME, t: float):\n",
    "    '''\n",
    "    Checks if a partition is t-close.\n",
    "\n",
    "    Parameters:\n",
    "        ...\n",
    "        - t: distance between the distribution of the sensitive column within the partition and the global (true) distribution\n",
    "\n",
    "    Returns:\n",
    "        - True if the partition satisfies t-closeness. False otherwise\n",
    "    '''\n",
    "    ...\n",
    "\n",
    "def is_valid(CHANGE_ME, k: int, l: Union[None, int] = None, t: Union[None, float] = None):\n",
    "    '''\n",
    "    Checks if a partition is valid according to the required anonymity.\n",
    "\n",
    "    Parameters:\n",
    "        ...\n",
    "        - k: number of different rows per partition\n",
    "        - l: number of distinct values for the sensitive column within the partition\n",
    "        - t: distance between the distribution of the sensitive column within the partition and the global (true) distribution\n",
    "\n",
    "    Returns:\n",
    "        - True if the partition satisfies t-closeness. False otherwise\n",
    "    '''\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dimensions(CHANGE_ME) -> Dict[str, float]:\n",
    "    '''\n",
    "    Analyzes the width of each quasi-identifier column within the partition to decide\n",
    "    on which one to perform the partitioning.\n",
    "\n",
    "    !TIP: You need to compute relative widhts with respect to the entire database;\n",
    "    otherwise the numerical columns will be always the chosen ones!\n",
    "\n",
    "    rel_width = partition_width / global_width\n",
    "    \n",
    "    The column with the widest relative range is finally chosen.\n",
    "\n",
    "    Parameters:\n",
    "        ...\n",
    "\n",
    "    Returns:\n",
    "        - A dictionary containing the width for each quasi-identifier column.\n",
    "    '''\n",
    "\n",
    "    widths = {}\n",
    "    \n",
    "    # TODO: Compute widths\n",
    "    ...\n",
    "\n",
    "    # Sorts columns by width\n",
    "    return dict(sorted(widths.items(), key=lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(CHANGE_ME) -> Tuple:\n",
    "    '''\n",
    "    Splits the partition on the specified quasi-identifier column.\n",
    "\n",
    "    The split is performed on the median value (for categorical the middle point is computed)\n",
    "\n",
    "    Parameters:\n",
    "        ...\n",
    "\n",
    "    Returns:\n",
    "        - A tuple containing the two halves of the partition\n",
    "    '''\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_partitions(database: pd.DataFrame, quasi_identifiers: List[str], sensitive_column: str,\n",
    "                     k: int, l: Union[int, None]=None, t: Union[float, None]=None) -> List[List[int]]:\n",
    "    '''\n",
    "    Builds partitions on the given dataset, so that each one satisfies the specified anonymity.\n",
    "\n",
    "    Parameters:\n",
    "        - database: entire database from which the partition is extracted\n",
    "        - quasi_identifiers: names of the quasi-identifier columns\n",
    "        - sensitive_column: name of the sensitive column\n",
    "        - k: number of different rows per partition\n",
    "        - l: number of distinct values for the sensitive column within the partition\n",
    "        - t: distance between the distribution of the sensitive column within the partition and the global (true) distribution\n",
    "\n",
    "    Returns:\n",
    "        - List of partitions (each partition is a list of indices from the original database)\n",
    "    '''\n",
    "\n",
    "    # Partitions that cannot be splitted any more (final partitions)\n",
    "    partitions = []\n",
    "    # TODO: Queue those partitions to be processed. Initially, the entire database is the unique available partition!\n",
    "    queue = [...]\n",
    "\n",
    "    while queue:\n",
    "        partition = queue.pop(0)\n",
    "        widths = analyze_dimensions(...)\n",
    "        \n",
    "        # Ensure that widths are sorted!\n",
    "        for qi in widths:\n",
    "            lp, rp = split(...)\n",
    "            # Check if both partitions are valid. If they are not valid, we will try to\n",
    "            # split them using the next quasi-identifier (sorted by width)\n",
    "            if is_valid(...) and is_valid(...):\n",
    "                # We will try to continue to divide each split in the upcoming iterations\n",
    "                queue.extend((lp, rp))\n",
    "                break\n",
    "        else:\n",
    "            # This else is only executed if the for loop is finished without performing a break!\n",
    "            # We will only end up here if no valid split is found on any column --> final partition\n",
    "            # TODO: Be careful here if you work with indices instead of database slices!! You may need to update this append!\n",
    "            partitions.append(partition)\n",
    "        \n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize_numerical(column: pd.Series) -> str:\n",
    "    '''\n",
    "    Generalizes a numerical column by computing the min-max range.\n",
    "\n",
    "    Parameters:\n",
    "        - column: column values to be generalized\n",
    "\n",
    "    Returns:\n",
    "        - Generalized value for the entire sample\n",
    "    '''\n",
    "\n",
    "    ...\n",
    "    \n",
    "def generalize_categorical(column: pd.Series) -> str:\n",
    "    '''\n",
    "    Generalizes a categorical column by grouping all the possible values.\n",
    "\n",
    "    Parameters:\n",
    "        - column: column values to be generalized\n",
    "\n",
    "    Returns:\n",
    "        - Generalized value for the entire sample\n",
    "    '''\n",
    "    \n",
    "    ...\n",
    "\n",
    "def generalize(partitions: List[pd.DataFrame], \n",
    "               quasi_identifiers: List[str], \n",
    "               sensitive_column: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Generalizes each one of the partitions defined for the database.\n",
    "\n",
    "    Parameters:\n",
    "        - partitions: list of partitions\n",
    "        - quasi_identifiers: names of the quasi-identifier columns\n",
    "        - sensitive_column: name of the sensitive column\n",
    "\n",
    "    Returns:\n",
    "        - A DataFrame with generalized values for each partition\n",
    "    '''\n",
    "\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for num_partition, partition in enumerate(partitions):\n",
    "\n",
    "        for ix in partition.index:\n",
    "    \n",
    "            row = dict()\n",
    "\n",
    "            # Fill quasi-identifier values\n",
    "            ...\n",
    "\n",
    "            # The value of the sensitive column, the original index,\n",
    "            # and the partition number must be kept for traceability\n",
    "            row[sensitive_column] = partition.loc[ix, sensitive_column]\n",
    "            row['index'] = ix\n",
    "            row['partition'] = num_partition\n",
    "            result.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(result)\n",
    "    df.set_index('index', inplace=True, drop=True)\n",
    "    df.index.name = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize(database: pd.DataFrame, quasi_identifiers: List[str], sensitive_column: str,\n",
    "              k: int, l: Union[int, None]=None, t: Union[float, None]=None) -> pd.DataFrame:\n",
    "    '''\n",
    "    Anonymizes a database acording to the required paramters.\n",
    "\n",
    "    Parameters:\n",
    "        - database: entire database from which the partition is extracted\n",
    "        - quasi_identifiers: names of the quasi-identifier columns\n",
    "        - sensitive_column: name of the sensitive column\n",
    "        - k: number of different rows per partition\n",
    "        - l: number of distinct values for the sensitive column within the partition\n",
    "        - t: distance between the distribution of the sensitive column within the partition and the global (true) distribution\n",
    "\n",
    "    Returns:\n",
    "        - List of partitions\n",
    "    '''\n",
    "    partitions = build_partitions(database, quasi_identifiers, sensitive_column, k, l=l, t=t)\n",
    "    return generalize(partitions, quasi_identifiers, sensitive_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, quasi_identifiers, sensitive_column = build_data(type='adult', n=5000, path='anonymity_data/adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anonymize(df, quasi_identifiers, sensitive_column, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anonymize(df, quasi_identifiers, sensitive_column, k=2, l=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anonymize(df, quasi_identifiers, sensitive_column, k=2, l=2, t=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "Briefly discuss how the different values of *k*, *l*, and *t* affect the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
